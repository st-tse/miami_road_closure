{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data stuff\n",
    "import pandas as pd\n",
    "\n",
    "#Modelling\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#NLP\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "#other\n",
    "from tqdm import tqdm_notebook\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data for Modeling\n",
    "- Specifying date range and road for model\n",
    "    - Code below refers only to `day_read` and `road_dir`. \n",
    "    - `start_day`, `end_day` and `road_dir` should be set here. \n",
    "- Formatting X to Input in Vectorizer\n",
    "    - model is built on one day of data \n",
    "    - data is broken down by hour\n",
    "    - all tweets from that hour are concatenated together\n",
    "    \n",
    "#### Data Dictionary\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|time|Object (datetime)|data2|Time of tweet (EDT), formatted yyyy-mm-dd hh:00:00+00:00; covers time span of hh:00 to hh:59|\n",
    "|tweets|Object (string)|data2|Concatenated tweets pulled from traffic sites during that hour|  \n",
    "\n",
    "- Formatting Y to Train X data\n",
    "    - Y is built off of manually input values from reliable traffic twitter sites\n",
    "    - Data is entered by hour \n",
    "    - 6 Major roadways represented in both directions\n",
    "\n",
    "#### Data Dictionary\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|date|Object (datetime)|closed|Time of tweet (EDT), formatted yyyy-mm-dd hh:00:00+00:00; covers time span of hh:00 to hh:59|\n",
    "|1-95 North|int|closed|Staus of major roadway in direction indicated (0 = no lane closures or incidents for duration of hour, 1 = any type of lane closure or incident during hour duration)|  \n",
    "|1-95 South|int|closed|Staus of major roadway in direction indicated (0 = no lane closures or incidents for duration of hour, 1 = any type of lane closure or incident during hour duration)|  \n",
    "|95 Express North|int|closed|Staus of major roadway in direction indicated (0 = no lane closures or incidents for duration of hour, 1 = any type of lane closure or incident during hour duration)|  \n",
    "|95 Express South|int|closed|Staus of major roadway in direction indicated (0 = no lane closures or incidents for duration of hour, 1 = any type of lane closure or incident during hour duration)| \n",
    "|I-195 East|int|closed|Staus of major roadway in direction indicated (0 = no lane closures or incidents for duration of hour, 1 = any type of lane closure or incident during hour duration)|  \n",
    "|I-195 West|int|closed|Staus of major roadway in direction indicated (0 = no lane closures or incidents for duration of hour, 1 = any type of lane closure or incident during hour duration)| \n",
    "|SR 826 North|int|closed|Staus of major roadway in direction indicated (0 = no lane closures or incidents for duration of hour, 1 = any type of lane closure or incident during hour duration)|  \n",
    "|SR 826 South|int|closed|Staus of major roadway in direction indicated (0 = no lane closures or incidents for duration of hour, 1 = any type of lane closure or incident during hour duration)| \n",
    "|US-1 North|int|closed|Staus of major roadway in direction indicated (0 = no lane closures or incidents for duration of hour, 1 = any type of lane closure or incident during hour duration)|  \n",
    "|US-1 South|int|closed|Staus of major roadway in direction indicated (0 = no lane closures or incidents for duration of hour, 1 = any type of lane closure or incident during hour duration)| \n",
    "\n",
    "- Merging data2 and closed2 such that only hours with data remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_day = 23 #  Day refers to a day in July 2019\n",
    "end_day = 30 # Range is inclusive (end day is included in data)\n",
    "road_dir = 'I-95 North'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_X(day_read):\n",
    "    data = pd.read_csv('Datasets/timeloop_'+day_read+'.csv')\n",
    "    data.drop(columns=['User','User_ID','Geo'], inplace = True)\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data['Date'] = data.assign(Date=data['Date'].dt.round('H'))['Date']\n",
    "    times = []\n",
    "    times.append(data['Date'][0])\n",
    "\n",
    "    for i in tqdm_notebook(data.index):\n",
    "        time = data['Date'][i]\n",
    "        if time != times[len(times)-1]:\n",
    "            times.append(time)\n",
    "        \n",
    "    dic = {'time': [], 'tweets': []}\n",
    "\n",
    "    for hour in tqdm_notebook(times):\n",
    "        total = ''\n",
    "        tweets = list(data[data['Date'] == hour]['Tweet'])\n",
    "        for twit in tweets:\n",
    "            total += str(twit)\n",
    "        dic['time'].append(hour)\n",
    "        dic['tweets'].append(total)\n",
    "    data2 = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "    data2.set_index('time', inplace=True)\n",
    "    data2.sort_index(inplace=True)\n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22e9f55acfe4caba32fce50e4d585cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e6569ab08e46229a5c9f340bbaa4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6f3f5c3f81450c93f5b72e21ace83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97fc68901434f5c99649f8c4089501f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6984b06675304738bb77793a2133e93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cbd317047244ab9f5723a4b98fb941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41afab94ca6460f82b0cdabb5e1f387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b3ae8eaae74168acddc5df8bb4d74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa40c94b1cf46dba2ca6f9cbd4de0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbe9373660b4d7b873e93c107588e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f410525aa6453c94250f91cc664231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b748c5497cb48fa9dbc43660221d9f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3461e297dc7640efaf2872c3e1b3d776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d34c8aa1bbd4013b0e89108046fe4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adcaf7aa2ebd4537b7d9399242bbd6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8b47693a5645d2bf69c57a43390b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_X = pd.DataFrame()\n",
    "\n",
    "for day in range(start_day, end_day+1):\n",
    "    cleaned_X = clean_X('2019-07-' + str(day))\n",
    "    data_X = pd.concat([cleaned_X, data_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X.to_csv('./Datasets/data_X_all_tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed = pd.read_csv('Datasets/manual_y - PDT.csv')\n",
    "closed.rename({'Unnamed: 0': 'Date'}, axis=1, inplace=True)\n",
    "closed['Date'] = pd.to_datetime(closed['Date'], utc=True) + timedelta(hours=7)\n",
    "# added UTC=True to make formatting match X table\n",
    "closed.set_index('Date', inplace=True)\n",
    "closed.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.concat([data_X, closed], axis=1, join='outer').dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model\n",
    "- Train/Test Split (skipped for small initial dataset)\n",
    "- Create Pipeline\n",
    "- Gridsearch Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    81\n",
       "1    36\n",
       "Name: I-95 North, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data['I-95 North'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_data['tweets']\n",
    "y = model_data[road_dir]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes\n",
    "\n",
    "Best Model Performance: \n",
    "- Train score = 0.87\n",
    "- Test score = 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvs: 0.7471264367816092\n",
      "train score: 0.8735632183908046\n",
      "test score: 0.8333333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nb__alpha': 0.6,\n",
       " 'vec__max_df': 0.6,\n",
       " 'vec__max_features': 2000,\n",
       " 'vec__min_df': 1,\n",
       " 'vec__ngram_range': (2, 5),\n",
       " 'vec__stop_words': 'english'}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(token_pattern='[a-zA-z]+ | [A-Za-z]+\\-*\\d+\\W(?:[sS]outh|[Nn]orth|East|West|[NSEW]{1,2}|[nswe]{1,2})*')),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "pipe_params = {\n",
    "    'vec__stop_words': ['english'],\n",
    "    'vec__max_features': [2000],\n",
    "    'vec__min_df': [1],\n",
    "    'vec__max_df': [.6],\n",
    "    'vec__ngram_range': [(2,5)],\n",
    "    'nb__alpha': [.6]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print('cvs:', gs.best_score_)\n",
    "print('train score:', gs.score(X_train, y_train))\n",
    "print('test score:', gs.score(X_test, y_test))\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "\n",
    "Best Model Performance: \n",
    "- Train score = \n",
    "- Test score = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(token_pattern='[a-zA-z]+ | [A-Za-z]+\\-*\\d+\\W(?:[sS]outh|[Nn]orth|East|West|[NSEW]{1,2}|[nswe]{1,2})*')),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'vec__stop_words': ['english'],\n",
    "    'vec__max_features': [1000, 2000, 3000],\n",
    "    'vec__min_df': [1, 2],\n",
    "    'vec__max_df': [.5, .6],\n",
    "    'vec__ngram_range': [(2,5), (3,5)],\n",
    "    'rf__n_estimators': [3],\n",
    "    'rf__max_depth' : [6],\n",
    "    'rf__min_samples_split' : [.18],\n",
    "    'rf__criterion' : ['gini'],\n",
    "    'rf__min_samples_leaf' : [1],\n",
    "    'rf__max_features' : [.88]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print('cvs:', gs.best_score_)\n",
    "print('train score:', gs.score(X_train, y_train))\n",
    "print('test score:', gs.score(X_test, y_test))\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breaking out TFIDF \n",
    "- Vectorizing tweets is time consuming\n",
    "- Tuning models to high performing TFIDF parameters first\n",
    "- Run pipe param with vectorizer after other model parameters are tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    token_pattern='[a-zA-z]+ | [A-Za-z]+\\-*\\d+\\W(?:[sS]outh|[Nn]orth|East|West|[NSEW]{1,2}|[nswe]{1,2})*',\n",
    "    stop_words='english',\n",
    "    max_features=2000,\n",
    "    min_df=1,\n",
    "    max_df=.6,\n",
    "    ngram_range=(2,5)\n",
    ")\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_test_vec = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(('rf', RandomForestClassifier()))\n",
    "\n",
    "grid_params = {\n",
    "    'rf__n_estimators': [3],\n",
    "    'rf__max_depth' : [6],\n",
    "    'rf__min_samples_split' : [.18],\n",
    "    'rf__criterion' : ['gini'],\n",
    "    'rf__min_samples_leaf' : [1],\n",
    "    'rf__max_features' : [.88]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=grid_params, cv=3)\n",
    "gs.fit(X_train_vec, y_train)\n",
    "print('cvs:', gs.best_score_)\n",
    "print('train score:', gs.score(X_train_vec, y_train))\n",
    "print('test score:', gs.score(X_test_vec, y_test))\n",
    "gs.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
